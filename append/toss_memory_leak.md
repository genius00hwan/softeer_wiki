# 토스 페이먼츠 사례로 보는 기반 지식의 중요성.

## 토스 페이먼츠의 사례
토스의 서비스가 OOM Killer에 의해 프로세스가 종료되는 문제가 발생했다고 한다.

### 문제 상황
토스의 어떤 서비스가 OOM Killer에 의해 프로세스가 종료.

- 자바 11 환경
- 도커의 Pod 메모리 상한: 4GB
- JVM Heap 제한: 1.5GB

OOM Killer가 작동할 때 Java 프로세스가 4GB를 전부 사용하고 있었다.
Heap을 제외하면 약 2.5GB의 네이티브 메모리가 추가로 사용되고 있었는데, 이는 메타스페이스나 일반적인 JVM 네이티브 메모리 사용량으로는 설명되지 않는 수치였다.


### 문제를 찾는 과정
토스의 담당 팀은 문제의 원인을 찾기 위해 단순히 GC 문제라고 가정하지 않고, JNI/JNA 사용 여부, Direct Buffer, APM 에이전트 등 네이티브 메모리를 사용하는 요소들을 하나씩 검증했다. 

그러나 이들은 문제와 무관했다.
결국 범위를 리눅스 프로세스 레벨로 넓히고, jemalloc 기반 메모리 프로파일링 툴을 사용해 네이티브 메모리 사용량을 세분화해 본 결과, C2 JIT 컴파일러가 약 1.9GB를 점유하고 있는 것이 확인되었다.

C2-compiler: 서버용으로 설계된 JIT 컴파일러
- 자주 호출되는 메서드를 네이티브 코드로 변환해 Code Cache에 올리고 이를 장시간 유지

장기 운영 환경과 고트래픽 서비스에서는 호출 빈도가 높은 메서드가 기하급수적으로 늘어나며, 한 번 올린 코드를 거의 제거하지 않는 C2의 특성상 Code Cache가 지속적으로 커질 수밖에 없다. 

여기에 토스의 멀티 쓰레드 환경이 결합되면서 쓰레드 스택 메모리도 함께 증가했고, 이 두 요인이 합쳐져 네이티브 메모리가 한계에 도달하며 OOM Killer가 작동했다.

####  JIT과 Code Cache
C2 JIT(Server Compiler)은 성능 최적화를 위해 핫스팟(자주 호출되는 메서드)을 네이티브 코드로 변환해 Code Cache에 저장.

- 한 번 올라간 코드는 거의 내려가지 않음 → 장기 운영 시 Code Cache 점유 증가
- Code Cache는 GC 대상이 아니며, JVM이 자동으로 비우지 않음 -> 장기 운영 시 메모리 누수를 야기할 수 있음

#### 쓰레드 증가와 네이티브 스택
- 자바 쓰레드는 OS 쓰레드와 1:1 매핑되며, 각 쓰레드마다 Native Stack(기본 1MB)이 할당.
- 쓰레드가 수천 개까지 증가하면 네이티브 스택 메모리만 수 GB 사용할 수도 있음.

### 해결 graal compiler
해결을 위해 C1 컴파일러로 전환했을 때는 문제없이 안정적으로 동작했지만, C1은 인터프리터 의존도가 높아 CPU 사용률이 40%에서 70%까지 치솟았다. 

이를 근본적으로 해결하기 위해 Graal 컴파일러가 도입되었다. Graal은 Partial Escape Analysis와 스마트 인라이닝을 통해 불필요한 메서드의 JIT 컴파일을 줄이고, Code Cache를 더 효율적으로 관리한다.

#### Escape Analysis

Escape Analysis는 객체가 메서드나 쓰레드 범위를 벗어나지 않는지(escape하지 않는지)를 분석하는 최적화 기법
어떤 객체가 메서드를 벗어나지 않는 경우 Heap에 할당할 필요 없이 Stack에서 처리 -> Heap 메모리 사용이 줄고, + GC 부담이 줆

C2의 한계
- C2는 EA를 하지만, 조금이라도 Escape 가능성이 있으면 보수적으로 판단해 Heap에 올림 

#### Partial Escape Analysis (Graal)

Partial Escape Analysis(PEA) Graal이 EA를 더 세밀하게 수행하는 방식
- 
- C2: “이 객체가 메서드 밖으로 나갈 가능성이 조금이라도 있다면 Heap에 올려라
- Graal(PEA): Escape하는 경로와 안 하는 경로를 분리해, Escape하지 않는 경로에선 Stack/레지스터에만 두자.

-> 조건부로 Escape 여부를 판단해 Heap 할당을 최소화한다.

Heap 메모리 사용 감소로 네이티브 메모리 사용량도 감소 (JIT 컴파일 중 불필요한 메타데이터 유지가 줄어듦) -> GC 부담 줄어 성능 향상


#### 스마트 인라이닝(Smart Inlining)

인라이닝(Inlining) = 메서드 호출을 없애고, 호출부에 코드 자체를 복사하는 최적화

장점: 메서드 호출 오버헤드 감소, JIT이 추가 최적화(루프 언롤링 등)를 적용하기 쉬워짐
단점: 코드가 너무 커지면 Code Cache 점유가 늘고, + JIT 컴파일 시간이 증가.

C2의 인라이닝
- C2는 공격적인 인라이닝을 한다.
- 자주 호출되는 메서드라면 코드 크기가 커져도 인라이닝 
- Code Cache가 커지고 메모리 점유가 늘어남.

Graal의 스마트 인라이닝
- Graal은 메서드 호출 빈도, 코드 크기, Code Cache 사용량 등을 종합적으로 판단해 인라이닝 여부를 결정.
- 불필요하게 커지는 인라이닝은 억제 
- Code Cache 메모리 절약

> 결과적으로 C2 수준의 성능을 유지하면서도 네이티브 메모리 사용량이 안정화되었다.


### 배운 점 

#### 운영 환경을 고려
- 자바의 메모리 누수는 Heap 영역만이 아니라 Code Cache, Thread Stack 같은 네이티브 메모리 영역에서도 충분히 발생할 수 있다. 
- 특히 JIT 컴파일러는 GC처럼 Code Cache를 자동으로 관리하지 않으며, 장기 운영 환경에서 JIT의 성능 최적화 전략이 오히려 메모리 병목으로 변할 수 있다는 사실을 실무 사례로 확인했다. 
- 또한 JVM 메모리 문제를 분석할 때는 반드시 네이티브 스택과 Code Cache까지 함께 고려해야 한다.

#### 문제를 찾아가는 과정
- 단순히 “GC 문제일 것이다”라고 가정하지 않고, 계측 도구를 통해 영역별로 메모리 사용량을 추적하는 데이터 기반 접근이 중요하다. 
- 또한 JIT, Code Cache, Thread Stack 같은 JVM 내부 원리를 이해하고 있어야 문제의 근본 원인에 접근할 수 있다. 
- 단순히 JVM 옵션을 바꾸는 것이 아니라, 왜 이 옵션이 필요한지 논리적으로 설명할 수 있어야 한다.
- “JIT은 자주 쓰는 메서드를 Code Cache에 올린다”는 원리가 실제 운영 환경에서 네이티브 메모리 누수 문제로 직결될 수 있다는 점을 이 사례로 확인했다. 

> 문제 해결에 있어 균형 잡힌 선택이 필요하다는 점도 배웠다. C1 전환은 단순한 임시방편이었을 뿐이고, CPU 사용량이라는 새로운 병목을 초래했다. 
> 성능과 메모리 안정성을 모두 확보할 수 있는 Graal 같은 대안이 근본적인 해결책이었다.


---

### 참고
[토스ㅣSLASH 22 - Java Native Memory Leak 원인을 찾아서](https://www.youtube.com/watch?v=w4fWgLgop5U&t=137s)















